# Implementation Plan

## Phase 1: Project Setup & Foundation (Step 1-3)

### Step 1: Project Structure
Create the basic project structure with all directories and initial files.

```
project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration loader
â”‚   â”‚   â”œâ”€â”€ models.py               # Pydantic models
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chatbot.py         # Chatbot service
â”‚   â”‚   â”‚   â”œâ”€â”€ judge.py           # Judge service
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_adapter.py     # LLM provider adapter
â”‚   â”‚   â”‚   â””â”€â”€ orchestrator.py    # Flow orchestrator
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py            # Chat endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ criteria.py        # Criteria endpoints
â”‚   â”‚   â”‚   â””â”€â”€ websocket.py       # WebSocket handlers
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ prompts.py         # Prompt templates
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ criteria.yaml          # Judge criteria config
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatUI.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ JudgePanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPanel.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Message.tsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts             # API client
â”‚   â”‚   â”‚   â””â”€â”€ websocket.ts       # WebSocket client
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ index.ts           # TypeScript types
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### Step 2: Backend Foundation
1. Initialize Python project with UV (`uv init`)
2. Add dependencies using UV (`uv add fastapi pydantic boto3 pyyaml uvicorn pydantic-settings python-dotenv websockets`)
3. Create configuration loader for criteria.yaml
4. Implement basic Pydantic models (Message, JudgeEvaluation, Criterion)
5. Create AWS Bedrock adapter

**Files to create:**
- `pyproject.toml` with project metadata and dependencies
- `uv.lock` (auto-generated by UV)
- `config.py` - YAML loader and validation + AWS configuration
- `models.py` - Data models
- `llm_adapter.py` - AWS Bedrock adapter for Claude Sonnet 4.5
- `criteria.yaml` - Initial criteria configuration

### Step 3: Frontend Foundation
1. Create Vite + React + TypeScript project
2. Install dependencies (WebSocket client, UI library)
3. Set up basic routing and layout
4. Create TypeScript types matching backend models
5. Set up API client service

**Files to create:**
- `package.json` with dependencies
- Basic component structure
- `api.ts` - HTTP client
- `types/index.ts` - TypeScript interfaces

## Phase 2: Core Services (Step 4-6)

### Step 4: Judge Service
Implement the core judge functionality.

**Tasks:**
1. Create judge prompt templates
2. Implement criteria loading from config
3. Build evaluation logic:
   - Parse criteria
   - Construct evaluation prompt
   - Call LLM for scoring
   - Parse structured response
   - Calculate weighted score
4. Add support for both input and output evaluation
5. Implement threshold checking and regeneration decision

**Key Function:**
```python
async def evaluate_message(
    message: str,
    context: List[Message],
    evaluation_type: str = "output"
) -> JudgeEvaluation
```

### Step 5: Chatbot Service
Implement the chatbot functionality.

**Tasks:**
1. Create chatbot prompt templates
2. Implement context management (conversation history)
3. Build response generation:
   - Format conversation history
   - Call LLM
   - Handle streaming (optional)
4. Add refinement capability:
   - Accept judge feedback
   - Regenerate with improvements
5. Error handling and fallbacks

**Key Functions:**
```python
async def generate_response(
    user_message: str,
    conversation_history: List[Message]
) -> str

async def refine_response(
    original_response: str,
    judge_feedback: str,
    conversation_history: List[Message]
) -> str
```

### Step 6: Orchestrator
Implement the conversation flow controller.

**Tasks:**
1. Define conversation flow modes:
   - Simple mode (no feedback loop)
   - Feedback mode (iterative improvement)
   - Input critique mode
2. Implement flow logic:
   - Coordinate chatbot and judge calls
   - Manage iteration counting
   - Apply thresholds
   - Handle errors
3. Add state management for active conversations

**Key Function:**
```python
async def process_message(
    user_message: str,
    conversation_id: str,
    mode: str = "feedback"
) -> ConversationResult
```

## Phase 3: API & Communication (Step 7-8)

### Step 7: REST API Endpoints
Implement HTTP endpoints.

**Endpoints to create:**
1. `POST /api/chat` - Process message (simple, non-WebSocket)
2. `GET /api/chat/history/{conversation_id}` - Get history
3. `GET /api/criteria` - Get current criteria
4. `PUT /api/criteria` - Update criteria
5. `POST /api/judge/evaluate` - Manual evaluation
6. `GET /api/health` - Health check

**Implementation:**
- Create route handlers in `api/` directory
- Wire up services
- Add request/response validation
- Implement error handling

### Step 8: WebSocket Implementation
Implement real-time communication.

**Tasks:**
1. Create WebSocket endpoint (`/ws/chat`)
2. Implement connection management
3. Define event types and handlers:
   - Client events: `user_message`, `update_settings`
   - Server events: `judge_input_critique`, `chatbot_response`, `judge_result`, etc.
4. Integrate with orchestrator for real-time flow
5. Add proper error handling and reconnection logic

**WebSocket Flow:**
```
Client connects â†’ Server acknowledges
Client sends "user_message" event
Server emits "judge_input_critique" (if enabled)
Server emits "chatbot_generating"
Server emits "chatbot_response"
Server emits "judge_evaluating"
Server emits "judge_result"
If score < threshold:
  Server emits "chatbot_refining"
  Server emits "chatbot_response" (refined)
  Server emits "judge_evaluating"
  Server emits "judge_result"
Server emits "final_response"
```

## Phase 4: Frontend Implementation (Step 9-11)

### Step 9: Chat UI Component
Build the main chat interface.

**Features:**
1. Message list with scroll management
2. Message input field
3. Send button with loading state
4. Message components:
   - User messages
   - Assistant messages
   - System messages (judge feedback)
5. Typing indicators
6. Error displays

### Step 10: Judge Panel Component
Build the judge feedback display.

**Features:**
1. Overall score display (large, prominent)
2. Traffic light score visualization:
   - ðŸŸ¢ Green (70-100): Good quality
   - ðŸŸ  Orange (40-69): Needs improvement
   - ðŸ”´ Red (0-39): Poor quality
3. Criteria breakdown:
   - Each criterion with individual score and traffic light
   - Score thresholds configurable per criterion
4. Feedback text display
5. Iteration history (if multiple refinements)
6. Collapsible/expandable sections

**Traffic Light Logic:**
```typescript
function getTrafficLight(score: number, thresholds?: {good: number, warn: number}): string {
  const good = thresholds?.good ?? 70;
  const warn = thresholds?.warn ?? 40;
  if (score >= good) return 'ðŸŸ¢';
  if (score >= warn) return 'ðŸŸ ';
  return 'ðŸ”´';
}
```

### Step 11: Settings Panel Component
Build configuration interface.

**Features:**
1. Criteria editor:
   - Enable/disable each criterion
   - Adjust weights (sliders)
   - View descriptions
2. Feature toggles:
   - Enable input critique
   - Enable feedback loop
   - Show iteration history
3. Profile selector (strict/moderate/lenient)
4. Save/reset buttons
5. Real-time preview of changes

## Phase 5: Integration & Polish (Step 12-14)

### Step 12: Frontend-Backend Integration
Connect all pieces together.

**Tasks:**
1. Implement WebSocket client in frontend
2. Connect UI events to WebSocket messages
3. Handle server events and update UI
4. Implement reconnection logic
5. Add loading states throughout
6. Test complete user flows

### Step 13: Configuration & Criteria
Finalize the criteria system.

**Tasks:**
1. Create comprehensive default criteria set
2. Add example profiles (strict, moderate, lenient)
3. Implement criteria validation
4. Add criteria documentation
5. Create admin UI for criteria (if time allows)
6. Test criteria modification and hot-reload

### Step 14: Testing & Documentation
Finalize the POC.

**Tasks:**
1. Test all conversation flows
2. Test error scenarios
3. Test with different LLM providers
4. Create user documentation
5. Create demo scenarios
6. Add inline code comments
7. Update README with:
   - Setup instructions
   - API documentation
   - Configuration guide
   - Example use cases

## Phase 6: Enhancements (Optional)

### Optional Features (if time permits)
1. **Conversation Persistence**: Save/load conversations
2. **Multi-user Support**: Handle multiple simultaneous users
3. **Prompt Templates UI**: Edit prompts from frontend
4. **Judge Explanations**: Detailed reasoning for scores
5. **A/B Testing**: Compare responses with/without judge
6. **Analytics Dashboard**: Track scores over time
7. **Export Functionality**: Export conversations with scores
8. **Custom Criteria Creation**: UI for creating new criteria

## Estimated Timeline

- **Phase 1** (Setup): 2-3 hours
- **Phase 2** (Core Services): 4-5 hours
- **Phase 3** (API): 2-3 hours
- **Phase 4** (Frontend): 4-5 hours
- **Phase 5** (Integration): 2-3 hours
- **Phase 6** (Optional): 2-4 hours

**Total: 14-19 hours for core POC**

## Prerequisites Before Starting

Please confirm:
1. âœ“ Python version (3.11+)
2. âœ“ Node.js version (18+)
3. âœ“ AWS Bedrock access:
   - [x] AWS account with Bedrock enabled
   - [x] AWS credentials (Access Key ID & Secret Access Key)
   - [x] Claude Sonnet 4.5 model access in AWS region
4. âœ“ LLM Configuration:
   - Chatbot: Claude Sonnet 4.5 (via AWS Bedrock)
   - Judge: Claude Sonnet 4.5 (via AWS Bedrock)

## Questions to Clarify

1. âœ“ **LLM Provider**: AWS Bedrock with Claude Sonnet 4.5
2. **UI Library**: Any preference for frontend UI components? (Material-UI, Ant Design, Chakra UI, shadcn/ui)
3. **Persistence**: Should conversations be saved, or purely in-memory for POC?
4. **Deployment**: Do you need Docker setup for easy deployment?
5. **Criteria Focus**: Any specific domains/criteria that are most important? (e.g., government/legal focus)

## Documentation Maintenance

Throughout the implementation, all changes will be reflected in the markdown documentation files:
- **docs/planning/instructions.md** - Updated with any conceptual or feature changes
- **docs/planning/architecture.md** - Updated with technical architecture modifications
- **docs/planning/implementation-plan.md** - Updated with progress and any plan adjustments
- **docs/planning/project-structure.md** - Updated when files/folders are added or reorganized

This ensures documentation stays in sync with the actual implementation.

## Next Steps

1. Review this implementation plan
2. Confirm/modify the approach
3. Answer clarifying questions above
4. Validate architecture.md and instructions.md
5. Give go-ahead to start implementation

Once approved, I'll begin with Phase 1!
